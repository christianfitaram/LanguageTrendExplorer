# ğŸŒ Language Trend Explorer

A modular NLP pipeline designed to scrape, clean, classify, summarize, analyze, and store trending linguistic content from real-world news sources.

Built for developers and data/AI enthusiasts looking for scalable, cleanly separated pipelines using Python, MongoDB, and modern NLP tools.

---

## ğŸ§  Project Overview

The **Language Trend Explorer** is split into modular, self-contained components:

- `pipeline_sample`: Scraping, cleaning, classification, summarization
- `pipeline_trend_analyzer`: Analyzing trends, predicting future trends
- `mongo/`: Managing storage in MongoDB (inserts, updates, and queries)

Each pipeline is independently runnable and easily integrable with others.

---

## ğŸ“ Directory Structure

```
LanguageTrendExplorer/
â”‚
â”œâ”€â”€ pipeline_sample/              # Pipeline for scraping and processing articles
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # Entry script to run the scraping & processing pipeline
â”‚   â”œâ”€â”€ classifier.py             # Classifies article content
â”‚   â”œâ”€â”€ custom_scrapers.py        # Web scrapers for non-API sources
â”‚   â”œâ”€â”€ exec_cleaner.py           # Cleans scraped text
â”‚   â”œâ”€â”€ exec_scraper.py           # Orchestrates multiple scrapers
â”‚   â”œâ”€â”€ news_api_scraper.py       # Uses NewsAPI to get news data
â”‚   â””â”€â”€ summarizer.py             # Summarizes long text content
â”‚
â”œâ”€â”€ pipeline_trend_analyzer/      # Performs trend prediction and analysis
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # Entry point to analyze stored data
â”‚   â”œâ”€â”€ prediction.py             # Trend prediction using ML/statistical methods
â”‚   â””â”€â”€ trend_analysis.py         # Extracts daily trends and builds frequency maps
â”‚
â”œâ”€â”€ mongo/                        # MongoDB access and operations
â”‚   â”œâ”€â”€ find.py                   # Queries for stored articles/trends
â”‚   â”œâ”€â”€ insert.py                 # Inserts processed data into MongoDB
â”‚   â””â”€â”€ update.py                 # Updates existing records in MongoDB
â”‚
â”œâ”€â”€ .gitignore                    # Ignore env files, IDE configs, and model weights
â”œâ”€â”€ requirements.txt              # Python dependencies (to be filled)
â””â”€â”€ README.md                     # Project documentation (this file)
```

---

## ğŸ”§ Setup & Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/LanguageTrendExplorer.git
cd LanguageTrendExplorer
```

### 2. Set up the Virtual Environment

```bash
python3 -m venv .venv
source .venv/bin/activate  # macOS/Linux
.venv\Scripts\activate     # Windows
```

### 3. Install Required Packages

> Create or use a `requirements.txt` file:
```bash
pip install -r requirements.txt
```

Example `requirements.txt`:
```text
requests
beautifulsoup4
nltk
scikit-learn
spacy
openai
pymongo
```

---

## â–¶ï¸ How to Use

### Run the Article Scraping & Processing Pipeline:

```bash
cd pipeline_sample
python main.py
```
NOTE: When running this for the first time will download the models used and may take a while.

This will:
- Scrape articles using NewsAPI and custom scrapers
- Clean and preprocess the data
- Classify the article's content
- Summarize long texts
- Pass results to the MongoDB handler (via `insert.py`)

---

### Run the Trend Analysis Pipeline:

```bash
cd pipeline_trend_analyzer
python main.py
```

This will:
- Retrieve processed articles from MongoDB
- Analyze trending nouns
- Predict future trends based on frequency and growth (on beta)
- Store/update trend results

---

## ğŸ“¦ Environment Variables (If Needed)

If using `.env` files for API keys:

Create a `.env` file at the root:

```dotenv
NEWSAPI_KEY=your_newsapi_key_here
MONGO_URI=mongodb://localhost:27017
```

And load them using `os.environ` or `dotenv`.

---

## ğŸ’¼ Use Cases

- ğŸ” NLP for language trend detection
- ğŸ—ï¸ Media monitoring and topic classification
- ğŸ“š Language learning insights from real data
- ğŸ“ˆ Predictive trend analytics with historic article data

---

## ğŸ“« Contact

**Christian RamÃ­rez**  
[GitHub: @christianfitaram](https://github.com/christianfitaram)  
Email: *christianfitaram@gmail.com*

---

## ğŸ“ License

MIT License â€” feel free to fork, modify, and build on it.

---
